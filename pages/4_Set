import streamlit as st # type: ignore
import pandas as pd
from zipfile import ZipFile
from zipfile import Path
import requests as rq
from io import StringIO
from datetime import date
import webbrowser
import os
import base64


st.set_page_config(
    page_title="SIAGOV",
    page_icon="datasets/siagov.ico",
    layout="wide",
)

#@st.cache(allow_output_mutation=True)
def get_base64_of_bin_file(png_file):
    with open(png_file, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()


def build_markup_for_logo(
    png_file,
    background_position="50% 10%",
    margin_top="10%",
    image_width="60%",
    image_height="",
):
    binary_string = get_base64_of_bin_file(png_file)
    return """
            <style>
                [data-testid="stSidebarNav"] {
                    background-image: url("data:image/png;base64,%s");
                    background-repeat: no-repeat;
                    background-position: %s;
                    margin-top: %s;
                    background-size: %s %s;
                }
            </style>
            """ % (
        binary_string,
        background_position,
        margin_top,
        image_width,
        image_height,
    )


def add_logo(png_file):
    logo_markup = build_markup_for_logo(png_file)
    st.markdown(
        logo_markup,
        unsafe_allow_html=True,
    )

add_logo("datasets/siagovlogonovo.png")

st.sidebar.divider()

### INICIALIZAR UNIDADE GESTORA ###
if 'ugs' not in st.session_state:
    st.session_state.ugs = '270001'

ugss = st.selectbox("Unidade Gestora", ('270001', '10001','90301'))
if st.button("Alterar"):
    st.session_state.ugs = ugss


st.write(st.session_state.ugs)

### CARGA DE DADOS EMPENHO ORIGINAL
dataatual = date.today()
ano = dataatual.year
mesA = dataatual.month
if dataatual.year > ano:
        mes = mesA + 1

@st.cache_resource
def load_empOri2024():
    empOrigt = []
    for i in range (1, mesA):
        arq = f"files/empenho_original{ano}mes{i}.gzip"
        if os.path.isfile(arq):
                emp = pd.read_csv(arq, sep=';', encoding='ISO-8859-1', compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}) #, index_col=[0]
                empOrigt.append(emp)
        else:
            st.write(f"Arquivo **empenho_original{ano}mes{mesA}** não disponível")
    empOrigr = pd.concat(empOrigt)
    empOrigr["CODIGO_MODALIDADE_LICITACAO"] = empOrigr["CODIGO_MODALIDADE_LICITACAO"].fillna(0)
    empOrigr["CODIGO_ACAO"] = empOrigr["CODIGO_ACAO"].fillna(0)
    empOrigr["CODIGO_FONTE_RECURSO"] = empOrigr["CODIGO_FONTE_RECURSO"].fillna(0)
    empOrigr["CODIGO_ITEM_DESPESA"] = empOrigr["CODIGO_ITEM_DESPESA"].fillna(0)
    return empOrigr

@st.cache_resource
def load_empSup2024():
    empSupt = []
    for i in range (1, mesA):
        arq = f"files/empenho_suplementacao{ano}mes{i}.gzip"
        if os.path.isfile(arq):
                emp = pd.read_csv(arq, sep=';', encoding='ISO-8859-1', compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}) #, index_col=[0]
                empSupt.append(emp)
        else:
            st.write(f"Arquivo **empenho_suplementacao{ano}mes{mesA}** não disponível")
    empSupr = pd.concat(empSupt)
    empSupr["CODIGO_MODALIDADE_LICITACAO"] = empSupr["CODIGO_MODALIDADE_LICITACAO"].fillna(0)
    empSupr["CODIGO_ACAO"] = empSupr["CODIGO_ACAO"].fillna(0)
    empSupr["CODIGO_FONTE_RECURSO"] = empSupr["CODIGO_FONTE_RECURSO"].fillna(0)
    empSupr["CODIGO_ITEM_DESPESA"] = empSupr["CODIGO_ITEM_DESPESA"].fillna(0)
    return empSupr

@st.cache_resource
def load_empAnu2024():
    empAnut = []
    for i in range (1, mesA):
        arq = f"files/empenho_anulacao{ano}mes{i}.gzip"
        if os.path.isfile(arq):
                emp = pd.read_csv(arq, sep=';', encoding='ISO-8859-1', compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}) #, index_col=[0]
                empAnut.append(emp)
        else:
            st.write(f"Arquivo **empenho_anulacao{ano}mes{mesA}** não disponível")
    empAnur = pd.concat(empAnut)
    empAnur["CODIGO_MODALIDADE_LICITACAO"] = empAnur["CODIGO_MODALIDADE_LICITACAO"].fillna(0)
    empAnur["CODIGO_ACAO"] = empAnur["CODIGO_ACAO"].fillna(0)
    empAnur["CODIGO_FONTE_RECURSO"] = empAnur["CODIGO_FONTE_RECURSO"].fillna(0)
    empAnur["CODIGO_ITEM_DESPESA"] = empAnur["CODIGO_ITEM_DESPESA"].fillna(0)
    empAnur['VALOR_EMPENHO'] = -empAnur['VALOR_EMPENHO']
    return empAnur

@st.cache_resource
def load_pagAnu2024():
    pagAnut = []
    for i in range (1, mesA):
        arq = f"files/pagamento_anulacao{ano}mes{i}.gzip"
        if os.path.isfile(arq):
                emp = pd.read_csv(arq, sep=';', encoding='ISO-8859-1', compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1}) #, index_col=[0]
                pagAnut.append(emp)
        else:
            st.write(f"Arquivo **pagamento_anulacao{ano}mes{mesA}** não disponível")
    pagAnur = pd.concat(pagAnut)
    pagAnur['VALOR_EMPENHO'] = -pagAnur['VALOR_DOCUMENTO']
    pagAnur['NUMERO_EMPENHO_ORIGEM'] = pagAnur['NUMERO_EMPENHO']
    pagAnur['DATA_DOCUMENTO'] = pd.to_datetime(pagAnur['DATA_DOCUMENTO'])#, format="%B", errors='ignore') #format="ISO8601" OU mixed
    pagAnur['DATA_EMPENHO'] = pagAnur['DATA_DOCUMENTO']
    pagAnur['CODIGO_TIPO_EMPENHO'] = pagAnur['CODIGO_TIPO_DOCUMENTO'] # GD
    pagAnur['DESCRICAO_TIPO_EMPENHO'] = pagAnur['DESCRICAO_TIPO_DOCUMENTO'] # GUIA DE DEVOLUCAO

    return pagAnur

@st.cache_resource
def itemdespesa():
     itemdesp = []
     arq = f"files/item_despesa_exercicio_2024.csv"
     if os.path.isfile(arq):
          itemdesp = pd.read_csv(arq, sep=';', encoding='ISO-8859-1')

     return itemdesp

###################################
### TRATAMENTO DOS EMPENHOS ###

totEmpOrig = load_empOri2024()

totEmpSup = load_empSup2024()

totEmpAnu = load_empAnu2024()

totPagAnu = load_pagAnu2024()
colunas = ['CODIGO_UNIDADE_GESTORA','NUMERO_EMPENHO_ORIGEM','CODIGO_MODALIDADE_LICITACAO','CODIGO_MOTIVO_DISPENSA_LICITACAO','DESTINO_DIARIAS','DATA_SAIDA_DIARIAS','DATA_CHEGADA_DIARIAS',
           'NOME_CREDOR', 'CPFCNPJ_CREDOR' ,'TIPO_CREDOR', 'CODIGO_MUNICIPIO', 'NOME_MUNICIPIO', 'NUMERO_PROCESSO_PAGAMENTO', 'NUMERO_CONTRATO',
           'CODIGO_UNIDADE_ORCAMENTARIA', 'CODIGO_FUNCAO','CODIGO_SUBFUNCAO','CODIGO_PROGRAMA','CODIGO_ACAO','CODIGO_FONTE_RECURSO','CODIGO_NATUREZA_DESPESA',
           'CODIGO_CATEGORIA_ECONOMICA_DESPESA', 'CODIGO_GRUPO_NATUREZA_DESPESA','CODIGO_MODALIDADE_APLICACAO_DESPESA','CODIGO_ELEMENTO_DESPESA','CODIGO_ITEM_DESPESA',
           'CODIGO_FINALIDADE_FIXACAO','NOME__FINALIDADE_FIXACAO','CODIGO_LICITACAO','ORCAMENTO_DEMOCRATICO']
totPagAnu = pd.merge(totPagAnu, totEmpOrig[colunas], how='left', on=['CODIGO_UNIDADE_GESTORA','NUMERO_EMPENHO_ORIGEM'])

itemdespesas = itemdespesa()

#st.write("itemdespesas")
#itemdespesas

df_ugs = pd.read_csv("files/unidade_gestora_2023.gzip", sep=';', encoding='ISO-8859-1', compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1})

st.write("resultado")
result = pd.concat([totEmpOrig,totEmpSup,totEmpAnu,totPagAnu])#, ignore_index=True, sort=False)
result['DATA_EMPENHO'] = pd.to_datetime(result['DATA_EMPENHO'])
result['MES_DOCUMENTO'] = result['DATA_EMPENHO'].dt.month_name()
result['NUM_MES_DOCUMENTO'] = result['DATA_EMPENHO'].dt.month

result = pd.merge(result, df_ugs[['CODIGO_UNIDADE_GESTORA','SIGLA_UNIDADE_GESTORA','NOME_UNIDADE_GESTORA']], how='left', on=['CODIGO_UNIDADE_GESTORA'])

result = pd.merge(result, itemdespesas[['CODIGO_NATUREZA_DESPESA','NOME_NATUREZA_DESPESA','CODIGO_ITEM_DESPESA','NOME_ITEM_DESPESA']], how='left', on=['CODIGO_NATUREZA_DESPESA','CODIGO_ITEM_DESPESA'])
coluna = ['EXERCICIO','CODIGO_UNIDADE_GESTORA']
result[coluna] = result[coluna].astype('category')
result['NOME_ITEM_DESPESA'] = result['NOME_ITEM_DESPESA'].fillna('')
result ############# CARGA
result.to_pickle("files/consolidado.pkl.compress", compression="gzip")
df = pd.read_pickle("files/consolidado.pkl.compress", compression="gzip")
df

ugs = st.sidebar.selectbox("Código da Unidade Gestora", result["CODIGO_UNIDADE_GESTORA"].unique())
idespesa = st.sidebar.selectbox("Item de despesa",result["CODIGO_ITEM_DESPESA"].unique())
st.write('total unid gestora')
consulta1 = result.query(f"CODIGO_UNIDADE_GESTORA == {ugs} & CODIGO_MODALIDADE_LICITACAO == 4")
consulta1

st.write('total unid gestora e item despesa')
consulta = result.query(f"CODIGO_UNIDADE_GESTORA == {ugs} & CODIGO_ITEM_DESPESA == {idespesa}")
consulta

# para consulta de um df para outro df
consultaemp = consulta[['NUMERO_EMPENHO_ORIGEM']]
consultaemp
st.write('anulações')
#filtro = result.query(f"CODIGO_UNIDADE_GESTORA == {ugs} & NUMERO_EMPENHO_ORIGEM == {consultaemp}")
filtro = result[result['NUMERO_EMPENHO_ORIGEM'].isin(consultaemp['NUMERO_EMPENHO_ORIGEM'])]
#elementoFiltroAcao = nomeAcaoE[nomeAcaoE["CODIGO_ACAO"] == codAcaoE].iloc[0]
filtro = filtro.query(f"CODIGO_UNIDADE_GESTORA == {ugs}")
filtro

st.write('agrupado')
#grupo_item_despesa = consulta.groupby(['CODIGO_UNIDADE_GESTORA','NUMERO_EMPENHO_ORIGEM','NUM_MES_DOCUMENTO','NOME_ITEM_DESPESA']).sum(['VALOR_EMPENHO']).reset_index()
#grupo_item_despesa
table = pd.pivot_table(consulta1, values='VALOR_EMPENHO', index=['NOME_ITEM_DESPESA'], columns=['NUM_MES_DOCUMENTO'], aggfunc='sum')
table['TOTAL'] = table.sum(axis=1)
table

item_con = st.selectbox('Select Item de Despesa', sorted(consulta1['NOME_ITEM_DESPESA'].unique()))
con_item = consulta1[consulta1['NOME_ITEM_DESPESA'] == item_con]
con_item